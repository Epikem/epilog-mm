---
date: "2019-05-26"
title: "TIL 2019-05-26"
categories: "TIL"
tags: ["TIL"]
---

오늘 배운 것 & 한 것

----------

## vocabo

에러가 나는게, [여기](https://docs.bitnami.com/google/apps/elasticsearch/get-started/understand-default-config/) 설명에 나온대로 elasticsearch log를 확인해 보니, jaso analyzer 관련 클래스인 `JasoTokenizerFactory`에서 `NoSuchMethod`에러가 나고 있었다. 들어가 코드를 확인해 보니, vscode에서 `super(...)`콜에서 매개변수가 안맞다며 빨간 줄이 쳐지고 quick fix를 하니 부모의 시그니쳐에 맞게 한 매개변수가 삭제되었다. 삭제하고 빌드해서 s3에 올리고 원래 설치된것 삭제하고 url로 다시 설치했는데 또 실패하길래 왜지 하다가 생각해보니 또 elasticsearch 서비스 재시작이 필요한 것이었다. 서비스 재시작을 하니 드디어 성공적으로 kengdic 인덱스를 만들었다. 아 그리고 매핑 타입이 없어졌다는걸 봐서 일단 'logs' 타입을 빼고 PUT 요청을 넣었다. 전에 쓰던 인덱스 세팅이 두 가지 있는데 뭐였는지 까먹었다. 아마도 아래꺼일듯.

최종 요청 (아래꺼 씀.)

```json

PUT kengdic
{
  "settings":{
    "analysis":{
      "tokenizer":{
        "nori-user-dict":{
          "type":"nori_tokenizer",
          "decompound_mode":"mixed",
          "user_dictionary":"userdict_ko.txt"
        }
      },
      "analyzer":{
        "analyzer-kor":{
          "type":"custom",
          "tokenizer":"nori-user-dict"
        },
        "analyzer-eng":{
          "type":"custom",
          "tokenizer":"standard",
          "filter":[
            "lowercase"
          ]
        }
      }
    }
  },
  "mappings":{
    // "logs":{
      "properties":{
        "word":{
          // "type":"text",
          "type": "completion",
          "analyzer":"analyzer-kor"
        },
        "def":{
          // "type":"text",
          "type":"completion",
          "analyzer":"analyzer-eng"
        }
      }
    // }
  }
}

PUT kengdic
{
  "settings":{
    "analysis":{
      "filter": {
        "suggest_filter": {
          "type": "edge_ngram",
          "min_gram": 1,
          "max_gram": 50
        }
      },
      "tokenizer":{
        "nori-user-dict":{
          "type":"nori_tokenizer",
          "decompound_mode":"mixed",
          "user_dictionary":"userdict_ko.txt"
        },
        "jaso_search_tokenizer": {
          "type": "jaso_tokenizer",
          "mistype": true,
          "chosung": false
        },
        "jaso_index_tokenizer": {
          "type": "jaso_tokenizer",
          "mistype": true,
          "chosung": true
        }
        // "jaso_search_tokenizer": {
        //   "type": "nori_tokenizer",
        //   "mistype": true,
        //   "chosung": false
        // },
        // "jaso_index_tokenizer": {
        //   "type": "nori_tokenizer",
        //   "mistype": true,
        //   "chosung": true
        // }
      },
      "analyzer":{
        "analyzer-kor":{
          "type":"custom",
          "tokenizer":"nori-user-dict"
        },
        "analyzer-eng":{
          "type":"custom",
          "tokenizer":"standard",
          "filter":[
            "lowercase"
          ]
        },
        "kor-suggest_search_analyzer": {
          "type": "custom",
          "tokenizer": "jaso_search_tokenizer"
        },
        "kor-suggest_index_analyzer": {
          "type": "custom",
          "tokenizer": "jaso_index_tokenizer",
          "filter": [
            "suggest_filter"
          ]
        }
      }
    }
  },
  "mappings":{
    "logs":{
      "properties":{
        "word":{
          "type":"text",
          "store":true,
          "analyzer":"kor-suggest_index_analyzer",
          "search_analyzer":"kor-suggest_search_analyzer"
        },
        "def":{
          // "type":"text",
          "type":"completion",
          "analyzer":"analyzer-eng"
        }
      }
    }
  }
}

```

그런데 데이터를 다 넣어도 `GET _stats`의 결과에서 kengdic의 document count가 0이길래 왜인가 싶어 로그를 확인했더니, `rejecting mapping update to as the final mapping would have more than 1 type [_doc, logs]` 이런 에러가 떴다. 생각해보니, elasticsearch 버전 7쯤에서 매핑 타입이 없어졌다지만, 나는 scoop으로 설치한 구버전 logstash를 그대로 쓰고있어서 type을 지정 안 하면 전처럼 `logs` 타입으로 기본으로 넣으려 한 것이다. 그래서 logstash 문서에서 찾아보니 elasticsearch output 플러그인에서는 `document_type`으로 지정하면 된다고 해서 `document_type=>"_doc"`이렇게 하니 성공적으로 데이터가 들어가고 검색도 성공했다. 드디어!

드디어 클러스터 전체를 테스트할 차례가 왔다. 문제는 어디 가거나 잘 때마다 이 전체 설정을 반복해야하는데.. bash 스크립트로 짜야 하려나?

elasticsearch 서비스 생성 과정:

1. elasticsearch cluster certified by bitnami를 배포.
1. 배포 완료되면 elasticsearch-vm에 접속
1. vm에서 `jaso-analyzer`, `nori-analysis` 플러그인 설치. (`jaso-analyzer`는 aws s3에 올려놓고 퍼블릭으로 설정하면 주소로 바로 설치 가능.)
1. vm에서 `sudo touch /opt/bitnami/elasticsearch/config/userdict_ko.txt` 로 사용자 사전 파일 생성
1. vm에서 `sudo /opt/bitnami/ctlscript.sh restart elasticsearch`로 es 서비스 재시작(플러그인 로드)
1. es 서비스가 재시작되었으면 `kengdic` 인덱스 생성하기.
1. 로컬에서 logstash의 elasticsearch output 필터의 `user`, `password` 항목을 위에서 생성한 클러스터의 정보를 참고하여 업데이트

로컬과 구글 콘솔 gui와 원격 vm 환경이 조합되어있어 자동화가 어려워보인다.. gcp에서 현재 상태를 다시 docker image처럼 템플릿화해서 저장해둘 수 있으면 정말 좋겠다.

## tags

\#vocabo, #elasticsearch

## new tips

-

<!---->



----------
